{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segundo examen parcial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargamos el set de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris_data = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = iris_data.data\n",
    "Y_train = iris_data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### INGRESA TU CODIGO AQUI  ~ 2 lineas de codigo ######\n",
    "kneigh = KNeighborsClassifier(n_neighbors=5)  \n",
    "kneigh.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96666666666666667"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## EJECUTA LA CELDA, NO HAY QUE CAMBIAR NADA ##\n",
    "y_pred = kneigh.predict(X_train)\n",
    "\n",
    "accuracy_score(Y_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresion logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Ingresa el numero de iteraciones ##\n",
    "numero_maximo_iteraciones = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### INGRESA TU CODIGO AQUI  ~ 2 lineas de codigo ######\n",
    "## utiliza la variable numero_maximo_iteraciones ##\n",
    "logistic_classifier = LogisticRegression()\n",
    "logistic_classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95999999999999996"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = logistic_classifier.predict(X_train)\n",
    "\n",
    "## Imprime el accuracy para el modelo de regresion logistica ##\n",
    "#### INGRESA TU CODIGO AQUI  ~ 1 linea de codigo ######\n",
    "accuracy_score(Y_train,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desicion trees\n",
    "\n",
    "** Importante: ** Tener instalado el paquete graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### INGRESA TU CODIGO AQUI  ~ 2 lineas de codigo ######\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Imprime el accuracy para el desicion tree ##\n",
    "#### INGRESA TU CODIGO AQUI  ~ 2 lineas de codigo ######\n",
    "y_pred = decision_tree.predict(X_train)\n",
    "accuracy_score(Y_train,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualiza el desicion tree\n",
    "\n",
    "En la siguiente celda imprime el desicion tree, como lo vimos en la clase.\n",
    "Puedes consultar [aqui](https://youtu.be/axCtUSHe30Y?t=1180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### INGRESA TU CODIGO AQUI  ~ 3 lineas de codigo ######\n",
    "import graphviz\n",
    "dot_data = tree.export_graphviz(decision_tree, out_file=None,filled=True, rounded=True, special_characters=True) \n",
    "graph = graphviz.Source(dot_data)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real: 0 Regresion Logistica [0] K-nearest neighbors [0] Decision Tree [0]\n",
      "Real: 0 Regresion Logistica [0] K-nearest neighbors [0] Decision Tree [0]\n",
      "Real: 0 Regresion Logistica [0] K-nearest neighbors [0] Decision Tree [0]\n",
      "Real: 0 Regresion Logistica [0] K-nearest neighbors [0] Decision Tree [0]\n",
      "Real: 0 Regresion Logistica [0] K-nearest neighbors [0] Decision Tree [0]\n",
      "Real: 0 Regresion Logistica [0] K-nearest neighbors [0] Decision Tree [0]\n",
      "Real: 0 Regresion Logistica [0] K-nearest neighbors [0] Decision Tree [0]\n",
      "Real: 0 Regresion Logistica [0] K-nearest neighbors [0] Decision Tree [0]\n",
      "Real: 0 Regresion Logistica [0] K-nearest neighbors [0] Decision Tree [0]\n",
      "Real: 0 Regresion Logistica [0] K-nearest neighbors [0] Decision Tree [0]\n",
      "Real: 0 Regresion Logistica [0] K-nearest neighbors [0] Decision Tree [0]\n",
      "Real: 0 Regresion Logistica [0] K-nearest neighbors [0] Decision Tree [0]\n",
      "Real: 0 Regresion Logistica [0] K-nearest neighbors [0] Decision Tree [0]\n",
      "Real: 0 Regresion Logistica [0] K-nearest neighbors [0] Decision Tree [0]\n",
      "Real: 0 Regresion Logistica [0] K-nearest neighbors [0] Decision Tree [0]\n",
      "Real: 0 Regresion Logistica [0] K-nearest neighbors [0] Decision Tree [0]\n",
      "Real: 0 Regresion Logistica [0] K-nearest neighbors [0] Decision Tree [0]\n",
      "Real: 0 Regresion Logistica [0] K-nearest neighbors [0] Decision Tree [0]\n",
      "Real: 0 Regresion Logistica [0] K-nearest neighbors [0] Decision Tree [0]\n",
      "Real: 0 Regresion Logistica [0] K-nearest neighbors [0] Decision Tree [0]\n",
      "Real: 0 Regresion Logistica [0] K-nearest neighbors [0] Decision Tree [0]\n",
      "Real: 0 Regresion Logistica [0] K-nearest neighbors [0] Decision Tree [0]\n",
      "Real: 0 Regresion Logistica [0] K-nearest neighbors [0] Decision Tree [0]\n",
      "Real: 0 Regresion Logistica [0] K-nearest neighbors [0] Decision Tree [0]\n",
      "Real: 0 Regresion Logistica [0] K-nearest neighbors [0] Decision Tree [0]\n",
      "Real: 0 Regresion Logistica [0] K-nearest neighbors [0] Decision Tree [0]\n",
      "Real: 0 Regresion Logistica [0] K-nearest neighbors [0] Decision Tree [0]\n",
      "Real: 0 Regresion Logistica [0] K-nearest neighbors [0] Decision Tree [0]\n",
      "Real: 0 Regresion Logistica [0] K-nearest neighbors [0] Decision Tree [0]\n",
      "Real: 0 Regresion Logistica [0] K-nearest neighbors [0] Decision Tree [0]\n",
      "Real: 0 Regresion Logistica [0] K-nearest neighbors [0] Decision Tree [0]\n",
      "Real: 0 Regresion Logistica [0] K-nearest neighbors [0] Decision Tree [0]\n",
      "Real: 0 Regresion Logistica [0] K-nearest neighbors [0] Decision Tree [0]\n",
      "Real: 0 Regresion Logistica [0] K-nearest neighbors [0] Decision Tree [0]\n",
      "Real: 0 Regresion Logistica [0] K-nearest neighbors [0] Decision Tree [0]\n",
      "Real: 0 Regresion Logistica [0] K-nearest neighbors [0] Decision Tree [0]\n",
      "Real: 0 Regresion Logistica [0] K-nearest neighbors [0] Decision Tree [0]\n",
      "Real: 0 Regresion Logistica [0] K-nearest neighbors [0] Decision Tree [0]\n",
      "Real: 0 Regresion Logistica [0] K-nearest neighbors [0] Decision Tree [0]\n",
      "Real: 0 Regresion Logistica [0] K-nearest neighbors [0] Decision Tree [0]\n",
      "Real: 0 Regresion Logistica [0] K-nearest neighbors [0] Decision Tree [0]\n",
      "Real: 0 Regresion Logistica [0] K-nearest neighbors [0] Decision Tree [0]\n",
      "Real: 0 Regresion Logistica [0] K-nearest neighbors [0] Decision Tree [0]\n",
      "Real: 0 Regresion Logistica [0] K-nearest neighbors [0] Decision Tree [0]\n",
      "Real: 0 Regresion Logistica [0] K-nearest neighbors [0] Decision Tree [0]\n",
      "Real: 0 Regresion Logistica [0] K-nearest neighbors [0] Decision Tree [0]\n",
      "Real: 0 Regresion Logistica [0] K-nearest neighbors [0] Decision Tree [0]\n",
      "Real: 0 Regresion Logistica [0] K-nearest neighbors [0] Decision Tree [0]\n",
      "Real: 0 Regresion Logistica [0] K-nearest neighbors [0] Decision Tree [0]\n",
      "Real: 0 Regresion Logistica [0] K-nearest neighbors [0] Decision Tree [0]\n"
     ]
    }
   ],
   "source": [
    "## EJECUTA LA CELDA, NO HAY QUE CAMBIAR NADA ##\n",
    "for i in range(len(Y_train[:50])):\n",
    "    prediction_logistic = logistic_classifier.predict(X_train[i].reshape(1,-1))\n",
    "    prediction_kneigh = kneigh.predict(X_train[i].reshape(1,-1))\n",
    "    prediction_decision_tree = decision_tree.predict(X_train[i].reshape(1,-1))\n",
    "    real = Y_train[i]\n",
    "    print(\"Real:\",real,\"Regresion Logistica\",prediction_logistic, \\\n",
    "          \"K-nearest neighbors\",prediction_kneigh, \\\n",
    "          \"Decision Tree\", prediction_decision_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicciones diferentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regresion Logistica [2] K-nearest neighbors [1] Decision Tree [1]\n",
      "Regresion Logistica [2] K-nearest neighbors [2] Decision Tree [1]\n",
      "Regresion Logistica [1] K-nearest neighbors [2] Decision Tree [1]\n",
      "Regresion Logistica [2] K-nearest neighbors [2] Decision Tree [1]\n",
      "Regresion Logistica [2] K-nearest neighbors [1] Decision Tree [1]\n"
     ]
    }
   ],
   "source": [
    "## EJECUTA LA CELDA, NO HAY QUE CAMBIAR NADA ##\n",
    "exit_flag = 0\n",
    "\n",
    "for i in range(len(Y_train)):\n",
    "    prediction_logistic = logistic_classifier.predict(X_train[i].reshape(1,-1))\n",
    "    prediction_kneigh = kneigh.predict(X_train[i].reshape(1,-1))\n",
    "    prediction_decision_tree = decision_tree.predict(X_train[i].reshape(1,-1))\n",
    "    real = Y_train[i]\n",
    "    if( (real!= prediction_logistic) or (real!= prediction_kneigh) or (real!= prediction_decision_tree) ):\n",
    "        print(\"Regresion Logistica\",prediction_logistic, \\\n",
    "          \"K-nearest neighbors\",prediction_kneigh, \\\n",
    "          \"Decision Tree\", prediction_decision_tree)\n",
    "        exit_flag+= 1\n",
    "        if (exit_flag == 5):\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizando las predicciones de los tres modelos, para cada uno de los ejemplos, ¿Que clasificación le darías, si no todos los modelos dan el mismo resultado? \n",
    "\n",
    "## En la siguiente celda da una conclusión para cada ejemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "KNN determina los vecinos, por lo que debe haber una métrica de distancia. Esto implica que todas las características deben ser numéricas. Las métricas de distancia se pueden efectuar variando las escalas entre los atributos y también el espacio de alta dimensión.\n",
    "\n",
    "Los árboles de decisión, por otro lado, predicen una clase para un vector de entrada dado. Los atributos pueden ser numéricos o nominales, además de que son fáciles de interpretar a diferencia de KNN que son muy complejos y el modelo de red no es interpretable; no obstante su precisión suele ser alta. \n",
    "\n",
    "Ahora bien, KNN no requiere entrenamiento. La regresión logística requiere algo de entrenamiento. Por otro lado, la regresión logística no necesita ningún ajuste de parámetros. Además, la regresión logística aprende un clasificador lineal y predice las probabilidades, mientras que los KNN también pueden aprender los límites no lineales, pero predicen solo las etiquetas.\n",
    "\n",
    "\n",
    "Entonces, si quiere encontrar ejemplos similares, podría usar KNN. Si quiere clasificar ejemplos, puede usar DT. Sin embargo, ninguna de estas comparaciones te dice qué método tendrá un mejor rendimiento en general: son fundamentalmente diferentes, y uno puede encontrar ejemplos donde uno es mejor que el otro.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
